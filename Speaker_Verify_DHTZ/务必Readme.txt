这是一个简单的 说话人识别的 微项目。

1、数据来源于某个数据集，随便挑了5个说话人的1500条语音。

2、文件夹内已经将.wav文件的特征melspecc提取到了meldata_22k_trimed下面

3、所以你不需要运行提取特征的函数。直接解压文件夹以后，创建合适的python环境

4、然后运行 run main即可。

5、linux或者windows系统均可运行。

6、注意看需要安装的库。 主要是 torch \ torchaudio \ liborsa \ pathlib \ sklearn \ pickle

7、在运行的过程中，会自动生成Experiment/v1 文件，如果你运行出现了错误，那么删除 v1文件，重新运行main.py

8、这套代码已经在win电脑和mac电脑调试过，如果报错，大概率是因为你重复run了main.py但是没有删除v1文件夹。

9、本代码的学习 路线为：
     （1）预处理出特征文件夹。 Preprocess.py
  （2） 根据特征文件夹，创建mydataset。以及表单文件的创建（重要）。不同的任务的、不同的数据集创建表单的方式都不一样。 Mydatase.py
（3）模型文件 。Model.py 。主要是搞清楚模型的输入输出的含义以及维度，至于内部细节可以暂时不考虑。但是迟早也要学习各种模型的细节。
（4）训练文件夹。Train.py 。主要 学习 其应有的工具类方法。
（5）超参数类、实验开启函数。Create_Hparams.py 。这个文件规定了如何开启实验，以及每次开启实验的时候，可以修改哪些参数。
（6）最后可以 根据本 代码中使用到的一些库，去学习Pathlib、torch、torchaudio、librosa等库的基本使用。


10、由于时间关系，本代码没有写 验证类函数.朋友们可以自己去添加验证代码。
	提示；使用 with torch.no_grad ，并读取 验证表单。